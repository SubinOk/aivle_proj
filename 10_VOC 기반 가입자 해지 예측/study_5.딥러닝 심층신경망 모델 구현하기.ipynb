{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 안녕하세요^^ \n","# AIVLE 미니 프로젝트에 오신 여러분을 환영합니다.\n","* 본 과정에서는 실제 사례와 데이터를 기반으로 문제를 해결하는 전체 과정을 자기 주도형 실습으로 진행해볼 예정입니다.\n","* 앞선 교육과정을 정리하는 마음과 지금까지 배운 내용을 바탕으로 문제 해결을 해볼게요!\n","* 미니 프로젝트를 통한 문제 해결 과정 'A에서 Z까지', 지금부터 시작합니다!\n","---\n","## __VOC(Voice of Customer) 데이터를 활용한 가입자 해지 예측 모델링__\n",">#### 1. AIDU 기본 사용법 및 데이터 분석 준비하기\n",">#### 2. 데이터 탐색하기\n",">#### 3. 데이터 전처리하기\n",">#### 4. 머신러닝 모델 구현\n",">### __5. 딥러닝 심층신경망 모델 구현__"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# 코드실행시 경고 메시지 무시\n","import warnings\n","warnings.filterwarnings(action='ignore') "]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["#!pip install seaborn"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# 필요 라이브러리 임포트 하기\n","import numpy as np\n","import pandas as pd\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{},"source":["## Chapter 5. 딥러닝 심층신경망 모델 구현\n","이번시간에는 Python을 활용한 AI 모델링에서 딥러닝에 대해 실습해 보겠습니다. <br>\n","여기서는 딥러닝 모델 DNN에 대해 코딩하여 모델 구축해 보겠습니다.<br>\n","이론보다 실습이 더 많은 시간과 노력이 투자 되어야 합니다.<br>\n","\n","> 1. 데이터 가져오기\n","> 1. 데이터 전처리 (완료)\n","> 1. Train, Test 데이터셋 분할\n","> 1. 데이터 정규화 (MinMaxScaling, StandardScaling)\n","> 1. 딥러닝 모델 구현<br>\n","> 1. 딥러닝 성능 평가<br>\n","\n","### __1. 데이터 가져오기__"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# ROOT_PATH 확인 \n","import os\n","\n","WORK_SPACE = \"\"\n","\n","if os.getcwd() == '/content' :\n","  # 구글 드라이브 사용 시 \n","  ROOT_PATH = \"/content\" \n","else :\n","  ROOT_PATH = os.path.abspath('..')\n","\n","DATA_PATH = ROOT_PATH + '/data'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# voc_rcp_practice3.csv  데이터 읽어 들이기\n","df = pd.read_csv(DATA_PATH + \"/voc_rcp_practice3.csv\")\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.head()"]},{"cell_type":"markdown","metadata":{},"source":["\n","\n","\n","\n","\n","### __2. 데이터 전처리하기 - 완료__\n","\n","### __3. Train, Test  데이터셋 분할__\n","> ① Feature / Target 데이터 분리<br>\n","> ② Train / Test 데이터 Set 나누기\n","\n","\n","#### __① Feature / Target 데이터 분리__\n","- Feature는 X, Target은 y로 분리\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Feature는 Target('trm_yn') 제외한 나머지 \n","X = df.drop(columns=['trm_yn']).values\n","\n","# Target은 해지여부('trm_yn')\n","y = df['trm_yn'].values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(X.shape, y.shape)"]},{"cell_type":"markdown","metadata":{},"source":["\n","\n","\n","\n","\n","\n","#### __② Train / Test 데이터 Set 나누기__\n","- X, y 값을 가지고 7:3 비율로 Train, Test 을 나누세요.<br>\n","- train_test_split 시 stratify 옵션 사용 <br>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 라이브러리 임포트\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 데이터 Set 나누기 (Train:Test)\n","X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.3, stratify=y, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(X_train.shape, y_train.shape)"]},{"cell_type":"markdown","metadata":{},"source":["### __4. 데이터 스케일링(MinMaxScaler)__"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 라이브러리 임포트\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# 스케일러 호출\n","scaler = MinMaxScaler()\n","\n","# 스케일링 (Train, Test)\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 라이브러리 임포트\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Activation, Dropout\n","\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"]},{"cell_type":"markdown","metadata":{},"source":["\n","### __5. 딥러닝 모델 구현 (DNN)__\n","> ① 모델 생성하기 : Sequentioal 모델<br>\n","> ② 모델 컴파일 하기<br>\n","> ③ 모델 학습하기<br>\n","> ④ Callbacks 함수 설정하기 : EarlyStopping, ModelCheckpoint<br>\n","\n","\n","\n","#### __① 모델 생성하기 : Sequentioal 모델__\n","- 하이퍼 파라미터 설정 : batch_size = 1024, epochs = 20<br>\n","- hidden layer 3개 이상으로 모델을 구성<br>\n","-  과적합 방지하는 dropout을 설정하세요.<br>\n","\n","#### __A. 이진 분류용 DNN layer__\n","\n","![hidden Layer](https://github.com/gzone2000/TEMP_TEST/raw/master/hidden_layer1.PNG)<br>\n","[출처] https://subscription.packtpub.com/book/data/9781788995207/1/ch01lvl1sec03/deep-learning-intuition\n","\n","- __라이브러리 임포트__\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 라이브러리 임포트\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Activation, Dropout"]},{"cell_type":"markdown","metadata":{},"source":["- __모델 선언__\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 80개 input layer\n","# unit 4개 hidden layer\n","# unit 3개 hidden layer \n","# 1개 output layser : 이진분류\n","\n","model = Sequential()\n","model.add(Dense(4, activation='relu', input_shape=(80,)))\n","model.add(Dense(3, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))"]},{"cell_type":"markdown","metadata":{},"source":["- __모델 확인__"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["__[Dropout : 과적합 방지]__\n","\n","![dropout](https://github.com/gzone2000/TEMP_TEST/raw/master/dropout.PNG)<br>\n","[출처] https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 80개 input layer\n","# unit 4개 hidden layer\n","# dropout\n","# unit 3개 hidden layer \n","# dropout\n","# 1개 output layser : 이진분류\n","\n","model2 = Sequential()\n","model2.add(Dense(32, activation='relu', input_shape=(80,)))\n","model2.add(Dropout(0.3))\n","model2.add(Dense(16, activation='relu'))\n","model2.add(Dropout(0.3))\n","model2.add(Dense(1, activation='sigmoid'))"]},{"cell_type":"markdown","metadata":{},"source":["- __모델 확인__"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model2.summary()"]},{"cell_type":"markdown","metadata":{},"source":["#### __B. 다중 분류용 DNN layer__\n","\n","![다중분류](https://github.com/gzone2000/TEMP_TEST/raw/master/hidden_layer2.PNG)<br>\n","[출처] https://www.educba.com/dnn-neural-network/\n","\n","- __모델 선언__"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 18개 input layer\n","# unit 5개 hidden layer\n","# dropout\n","# unit 4개 hidden layer \n","# dropout\n","# 2개 output layser : 다중분류\n","\n","model3 = Sequential()\n","model3.add(Dense(5, activation='relu', input_shape=(80,)))\n","model3.add(Dropout(0.3))\n","model3.add(Dense(4, activation='relu'))\n","model3.add(Dropout(0.3))\n","model3.add(Dense(2, activation='softmax'))\n"]},{"cell_type":"markdown","metadata":{},"source":["- __모델 확인__"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model3.summary()"]},{"cell_type":"markdown","metadata":{},"source":["#### __② 모델 컴파일 하기__\n","\n","\n","\n","#### __A. 이진 분류 모델__\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.compile(optimizer='adam', \n","              loss='binary_crossentropy', \n","              metrics=['accuracy'])\n"]},{"cell_type":"markdown","metadata":{},"source":["#### __B. 다중 분류 모델__"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model3.compile(optimizer='adam', \n","              loss='categorical_crossentropy', \n","              metrics=['accuracy']) \n","\n","# 원-핫 인코딩이 안되어 있을 경우 다중 분류 모델의 loss는 'sparse_catesgorical_crossentropy'"]},{"cell_type":"markdown","metadata":{},"source":["\n","\n","#### __③ 모델 학습하기__\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["history = model.fit(X_train, y_train, \n","          validation_data=(X_test, y_test),\n","          epochs=20, \n","          batch_size=16)"]},{"cell_type":"markdown","metadata":{},"source":["#### __④ Callbacks 함수 설정하기 : EarlyStopping, ModelCheckpoint__\n","\n","- __라이브러리 임포트__\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 라이브러리 임포트 \n","from tensorflow.keras.callbacks import  EarlyStopping, ModelCheckpoint"]},{"cell_type":"markdown","metadata":{},"source":["- __Callback 선언__<br>\n","\n","#### __A. EarlyStopping__\n","모델을 더 이상 학습을 못할 경우(loss, metric 등의 개선이 없을 경우), 학습 도중 미리 학습을 종료시키는 콜백 함수 입니다.\n","> monitor : EalryStopping의 기준이 되는 값('val_loss'를 입력하면 val_loss가 더 이상 감소되지 않을 경우 적용)<br>\n","> min_delta : 개선된 것으로 간주하기 위한 최소한의 변화량<br>\n","> patience : monitor되는 값의 개선이 없을 때 최적의 값을 기준으로 몇 번의 epoch를 더 진행할 지 정하는 값<br>\n","> verbose : 화면에 상태 표시<br>\n","> mode : monitor가 최소가 되어야 하는 지, 최대가 되어야 하는지 ('val_accuracy'는 max, 'val_loss'는 min)<br>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["es = EarlyStopping(monitor='val_loss', patience=3, mode='min', verbose=1)"]},{"cell_type":"markdown","metadata":{},"source":["#### __B. ModelCheckpoint__\n","모델을 저장할 때 사용되는 콜백 함수입니다.\n","> filepath : 모델을 저장할 경로를 입력합니다. '파일명.h5'<br>\n","> 모델을 저장할 때, 기준이 되는 값을 지정합니다. ('val_loss'를 입력하면 validation set의 loss가 가장 적을 때 저장)<br>\n","> verbose : 화면에 상태 표시<br>\n","> save_best_only : True, False<br>\n","> mode : auto로 할 경우, 모델이 알아서 min, max 판단하여 모델 저장<br>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mc = ModelCheckpoint('my_checkpoint.h5', monitor='val_loss', save_best_only=True, verbose=1)"]},{"cell_type":"markdown","metadata":{},"source":["- __Callback을 설정하고 학습하기__<br>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model2.compile(optimizer='adam', \n","              loss='binary_crossentropy', \n","              metrics=['accuracy']) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["history = model2.fit(X_train, y_train, \n","          validation_data=(X_test, y_test),\n","          epochs=20, \n","          callbacks=[es, mc],\n","          batch_size=16,\n","          verbose=1)"]},{"cell_type":"markdown","metadata":{},"source":["#### __⑤ 모델 성능 평가(시각화)__ \n","- __성능 시각화__"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["performance = pd.DataFrame(model2.history.history)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["performance.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.plot(performance[['loss','val_loss']])\n","plt.legend(['loss', 'val_loss'])\n","plt.xlabel('Epochs')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.plot(performance[['loss','val_loss', 'accuracy','val_accuracy']])\n","plt.legend(['loss','val_loss', 'accuracy','val_accuracy'])\n","plt.xlabel('Epochs')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### __<font color=red>[실습]</font> 딥러닝 모델 구현하기__\n","\n","#### __<font color='red'>[Q]</font> 아래의 조건으로 DNN 모델을 구현해 보세요.__\n","- <font color='blue'>히든 레이어를 3개</font>로 모델을 구성하고 과적합 방지를 위한 <font color='blue'>dropout</font> 설정  <br>\n","- 모델의 optimizer는 'adam'을 사용하고 metrics는 'accuracy' 로 하여 컴파일하세요.<br>\n","- <font color='blue'>epochs는 20</font>으로 <font color='blue'>batch_size는 32</font>로 설정 <br>\n","- <font color='blue'>EarlyStopping</font> 콜백으로 정해진 epoch 동안 모니터링 지표가 향상되지 않을 때 훈련 중단( monitor는 'val_accuracy', patience는 5 설정)   <br>\n","- <font color='blue'>ModelCheckpoing</font> 콜백으로 validation performance가 가장 좋은 모델을 <font color='blue'>'이름.h5'</font> 파일로 저장하세요.\n","- 모델 학습 후 결과를 <font color='blue'>history_q</font> 변수에 저장하세요.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 여기에 입력하세요\n","# 라이브러리 임포트\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import *\n","\n","# input layer 확인 \n","inputs = Input(shape=(80, ))\n","x = inputs\n","\n","x = Dense(32, activation='relu')(x)\n","x = Dense(32, activation='relu')(x)\n","x = Dense(32, activation='relu')(x)\n","x = Dropout(0.2)(x)\n","\n","outputs = Dense(1, activation='sigmoid')(x)\n","\n","# 모델 선언 (뱐수 : model_q)\n","model_q = keras.models.Model(inputs, outputs)\n","\n","# 모델 확인\n","model_q.summary()\n","\n","# 모델 컴파일하기\n","model_q.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# callbacks 함수 설정\n","es = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, restore_best_weights=True)\n","chk = ModelCheckpoint('my_checkpoint_q.ckpt', monitor='val_loss', save_best_only=True, verbose=1)\n","\n","# 모델 훈련\n","history_q = model_q.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, callbacks=[es, chk], batch_size=32, verbose=1)\n","\n","model_q.load_weights(\"my_checkpoint_q.ckpt\")\n","model_q.save(\"my_name.h5\")"]},{"cell_type":"markdown","metadata":{},"source":["#### __<font color='red'>[Q]</font> 구현한 DNN 모델의 학습 결과를 'acc' 와 'val-acc'의 관계 그래프를 아래의 조건으로 표시하세요.__\n","- 그래프 제목은 'Acuuracy'로 표시하세요. <br>\n","- x축은 'Epochs' y축은 'Acc'로 표시하세요. <br>\n","- 범례를 'acc, 'val_acc'로 표시하세요. <br>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 여기에 입력하세요.\n","hist = pd.DataFrame(history_q.history)\n","\n","plt.plot(hist[['accuracy','val_accuracy']])\n","plt.legend(['acc','val_acc'])\n","plt.title('Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Acc')\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"9b951021aee1af8a38b85369796df8999da4b77ce8cdb748a95567db2c8a2d83"}}},"nbformat":4,"nbformat_minor":2}
